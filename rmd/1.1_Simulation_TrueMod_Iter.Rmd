---
title: "Simulation task 1 (Dirichlet Multinomial)"
author: "Siyuan Ma"
output: html_document
---

```{r set up}
knitr::opts_chunk$set(echo=FALSE)
library(magrittr)
```

```{r batchtools}
# Create batchtools registry
# batchtools::makeRegistry(file.dir = "r_batchtools_reg/sim/TrueMod_Iter")
batchtools::loadRegistry(file.dir = "r_batchtools_reg/sim/TrueMod_Iter",
                         writeable = TRUE)
rm(list = ls())
dir_output <- "results/Simulation/TrueMod/Iter"
dir.create(dir_output, showWarnings = TRUE, recursive = TRUE)
```

```{r jobs}
load("results/Simulation/TrueMod/tb_job.RData")
# simulation job grid
tb_job <- tb_job %>% 
  dplyr::filter(t_missing == 0,
                median_depth == 1e4,
                n == 1,
                method == "microTensor") %>% 
  dplyr::rename(i_job_old = i_job) %>% 
  dplyr::mutate(i_job = seq(1, dplyr::n()))
save(tb_job, file = paste0(dir_output, "/tb_job.RData"))
n_job <- nrow(tb_job)
n_job_each <- 20
```

```{r one job}
# fit decomposition methods to simulated data
one_job <- function(i_job) {
  library(magrittr)
  load(paste0(dir_output, "/tb_job.RData"))
  
  l_statistics <- list()
  for(ii_job in seq((i_job - 1) * n_job_each + 1, i_job * n_job_each)) {
    i_tb_job <- tb_job[ii_job, ]
  
    load("results/Simulation/TrueMod/params_n1.RData")
    
    ptilde <- params$p
    alpha0 <- i_tb_job$alpha0
    set.seed(i_tb_job$i_job_old)
    for(j in seq(1, dim(ptilde)[2]))
      for(k in seq(1, dim(ptilde)[3]))
        ptilde[, j, k] <- MCMCpack::rdirichlet(
          n = 1,
          alpha = alpha0 * params$p[, j, k])
    
    seq_depth <- 
      runif(n = dim(ptilde)[2] * dim(ptilde)[3],
            min = log(params$depth_range[1] * i_tb_job$median_depth), 
            max = log(params$depth_range[2] * i_tb_job$median_depth)) %>% 
      exp() %>% 
      round()
    
    N <- matrix(seq_depth, nrow = dim(ptilde)[2], ncol = dim(ptilde)[3])
    X_array <- ptilde
    for(j in seq(1, dim(ptilde)[2])) 
      for(k in seq(1, dim(ptilde)[3]))
        X_array[, j, k] <- rmultinom(n = 1, size = N[j, k], prob = ptilde[, j, k])
    
    fit_decomp <- microTensor::microTensor_iter(
      X = X_array, R = i_tb_job$R, 
      ortho_m = FALSE,
      nn_t = FALSE,
      control = list(
        L_init = 3,
        gamma = 2,
        init = "ctf",
        abs_tol = 1e-4,
        rel_tol = 1e-4,
        maxit = 5000,
        verbose = FALSE))
    
    fit_decomp_old <- microTensor::microTensor(
      X = X_array, R = i_tb_job$R, 
      weighted = TRUE,
      ortho_m = FALSE,
      nn_t = FALSE,
      control = list(
        L_init = 3,
        gamma = 2,
        init = "ctf",
        abs_tol = 1e-4,
        rel_tol = 1e-4,
        maxit = 5000,
        verbose = FALSE))
    
    
    ## evaluation
    n_iter <- length(fit_decomp) - 1
    phat_microTensor <- 
      apply(fit_decomp[[2]]$Yhat, c(2, 3), 
            function(x) {
              x <- x - max(x)
              return(exp(x) / sum(exp(x)))
            })
    phat_final <- 
      apply(fit_decomp[[n_iter + 1]]$Yhat, c(2, 3), 
            function(x) {
              x <- x - max(x)
              return(exp(x) / sum(exp(x)))
            })
    p_rel_diff <- mean(abs(phat_final - phat_microTensor) / abs(phat_final), na.rm = TRUE)
    
    fit_decomp_opt <- microTensor::extract_fits(fit_decomp[[n_iter + 1]]$l_fit)
    results_summary <- 
      microTensor::evaluate_fit(
        fit_decomp = fit_decomp_opt,
        p = params$p,
        X_array = X_array,
        R = 2)
    
    i_l_statistics <- 
      list(iters = n_iter,
           phi = fit_decomp[[n_iter]]$phi,
           phi_rel_diff = 
             abs(fit_decomp[[1]]$phi - fit_decomp[[n_iter]]$phi) / 
             abs(fit_decomp[[n_iter]]$phi),
           p_rel_diff = p_rel_diff,
           mean_L1_relative = mean(results_summary$mat_L1_relative, na.rm = TRUE))
   
    l_statistics <- c(l_statistics, list(i_l_statistics))
  }
  save(l_statistics, file = paste0(dir_output, "/l_statistics_", i_job, ".RData"))
  return(NULL)
}
```

```{r submit jobs}
# submit jobs to cluster through rbatchtools
batchtools::clearRegistry()
tb_ids <- batchtools::batchMap(one_job, 
                               i_job = seq(1, n_job / n_job_each))
batchtools::batchExport(list("dir_output" = dir_output,
                             "n_job_each" = n_job_each))
ncpus <- 1
partition <- "janson,janson_cascade"
walltime <- 3600
batchtools::submitJobs(ids = seq(1, 10),
                       resources =  list(ncpus = ncpus,
                                         partition = partition,
                                         walltime = walltime))
batchtools::submitJobs(ids = seq(11, n_job / n_job_each),
                       resources =  list(ncpus = ncpus,
                                         partition = partition,
                                         walltime = walltime))
```

```{r summarize results}
# old results
load("results/Simulation/TrueMod/tb_job.RData")
n_job_each <- 200
l_statistics <- seq(1, nrow(tb_job) / n_job_each) %>% 
  purrr::map(~ {
    load(paste0("results/Simulation/TrueMod/l_statistics_", .x, ".RData"))
    l_statistics
  }) %>% 
  purrr::reduce(c)

tb_job <- tb_job %>% 
  dplyr::filter(t_missing == 0,
                median_depth == 1e4,
                n == 1,
                method == "microTensor")

tb_results_old <- tb_job %>% 
  {dplyr::mutate(
    ., 
    mean_L1_relative = 
      l_statistics[.$i_job] %>%
      purrr::map_dbl("mean_L1_relative"))} %>% 
  rbind(tb_job %>% 
          {dplyr::mutate(
            ., 
            mean_L1_relative = 
              l_statistics[.$i_job] %>%
              purrr::map_dbl("mean_l1_relative_uw"),
            method = "microTensor (uw)")})

# New results
load(paste0(dir_output, "/tb_job.RData"))
n_job_each <- 20
l_statistics <- seq(1, nrow(tb_job) / n_job_each) %>% 
  purrr::map(~ {
    load(paste0(dir_output, "/l_statistics_", .x, ".RData"))
    l_statistics
  }) %>% 
  purrr::reduce(c)
tb_results <- tb_job %>% 
  dplyr::select(-i_job_old) %>% 
  dplyr::mutate(mean_L1_relative = l_statistics %>%
                  purrr::map_dbl("mean_L1_relative"),
                method = "microTensor (iter)")

tb_plot_results <- 
  rbind(
    tb_results_old, 
    tb_results) %>%
  dplyr::group_by(alpha0, t_missing, median_depth, method, n) %>%
  dplyr::summarise(log10_L1_relative = mean(log10(mean_L1_relative)),
                   sd_log10_L1_relative = sd(log10(mean_L1_relative)) / sqrt(dplyr::n())) %>% 
  dplyr::ungroup() %>% 
  dplyr::mutate(method = factor(method, 
                                levels = c("microTensor (uw)",
                                           "microTensor",
                                           "microTensor (iter)")))

colors <- smar:::gg_color_hue(
  values = c("CTF",
             "microTensor (uw)",
             "microTensor"))[c(2, 3)] %>% 
  c("microTensor (iter)" = "black")

p_figure <- tb_plot_results %>%
  dplyr::filter(n == 1) %>% 
  ggplot(aes(x = -log10(alpha0), y = log10_L1_relative, color = method)) +
  geom_point(position = position_dodge(width = 0.05)) +
  geom_errorbar(aes(ymin = log10_L1_relative - sd_log10_L1_relative,
                    ymax = log10_L1_relative + sd_log10_L1_relative),
                position = position_dodge(width = 0.05)) +
  geom_line(position = position_dodge(width = 0.05)) +
  scale_color_manual(values = colors) +
  theme_bw() +
  theme(legend.position = "bottom", 
        legend.title = element_blank(),
        legend.direction = "horizontal", 
        strip.background = element_blank()) +
  xlab(expression(paste("Dispersion (-", log[10], alpha[0], " for ", tilde(p)[ijk], ')'))) +
  ylab(expression(paste(log[10], " Relative ", L[1], " Difference (|", p[ijk], "-", hat(p)[ijk], 
                        "|/", p[ijk], ")")))

ggsave(p_figure, filename = "figures/figure3_simulation1/figure3_iter.pdf",
       width = 4.5, height = 4)
```